{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment17_RickyGunawan_DailyMinTemp_Lag7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2tRPzAKv1jR",
        "outputId": "8b63b1e2-7cda-4a1d-c6f0-3bb13a8128a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from statsmodels.tsa.ar_model import AR\n",
        "from statsmodels.tsa.arima_model import ARIMA\n",
        "\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wa24lkVU4hu"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')\n",
        " \n",
        "def timeseries_to_supervised(data, lag=1):\n",
        "    df = pd.DataFrame(data)\n",
        "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
        "    columns.append(df)\n",
        "    df = pd.concat(columns, axis=1)\n",
        "    return df\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)\n",
        "\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0ZGKXpW5o0"
      },
      "source": [
        "# **Dataset Daily Min Temp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soC1JGsfW-4B",
        "outputId": "d4ff15f7-4db6-4e8c-cb0d-342edc300420",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/BCML/datasets/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0, squeeze=False, date_parser=parser)\n",
        "dataset.head()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1981-01-01</th>\n",
              "      <td>20.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-02</th>\n",
              "      <td>17.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-03</th>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-04</th>\n",
              "      <td>14.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-05</th>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Temp\n",
              "Date            \n",
              "1981-01-01  20.7\n",
              "1981-01-02  17.9\n",
              "1981-01-03  18.8\n",
              "1981-01-04  14.6\n",
              "1981-01-05  15.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv_Me1QwXaoB",
        "outputId": "1419de69-e550-4577-9f2c-3d4a74983159",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "dataset.plot()\n",
        "plt.show()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNIsRnCpsaob"
      },
      "source": [
        "## **Penentuan Lag**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQFsJpoDjqHy"
      },
      "source": [
        "values = dataset.values\n",
        "size = int(len(values) * 0.75)\n",
        "train, test = values[0:size], values[size:len(values)]\n",
        "history = [x for x in train]\n",
        "predictions = []"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zvq0_aMhjs0v",
        "outputId": "3c0ec8fa-41af-4a8b-a5ed-410e2f7038e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "model = AR(train)\n",
        "model_fit = model.fit()\n",
        "print('Lag:', model_fit.k_ar)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Lag: 27\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5GtOxCFiqxC"
      },
      "source": [
        "dataset_values = dataset.values\n",
        "\n",
        "def evaluate_arima_model(X, arima_order):\n",
        "\t# prepare training dataset\n",
        "\ttrain_size = int(len(X) * 0.75)\n",
        "\ttrain, test = X[0:train_size], X[train_size:]\n",
        "\thistory = [x for x in train]\n",
        "\t# make predictions\n",
        "\tpredictions = list()\n",
        "\tfor t in range(len(test)):\n",
        "\t\tmodel = ARIMA(history, order=arima_order)\n",
        "\t\tmodel_fit = model.fit(disp=0)\n",
        "\t\tyhat = model_fit.forecast()[0]\n",
        "\t\tpredictions.append(yhat)\n",
        "\t\thistory.append(test[t])\n",
        "\t# calculate out of sample error\n",
        "\terror = mean_squared_error(test, predictions)\n",
        "\treturn error\n",
        "\n",
        "# evaluate combinations of p, d and q values for an ARIMA model\n",
        "def evaluate_models(dataset, p_values, d_values, q_values):\n",
        "\tdataset = dataset.astype('float32')\n",
        "\tbest_score, best_cfg = float(\"inf\"), None\n",
        "\tfor p in p_values:\n",
        "\t\tfor d in d_values:\n",
        "\t\t\tfor q in q_values:\n",
        "\t\t\t\torder = (p,d,q)\n",
        "\t\t\t\ttry:\n",
        "\t\t\t\t\tmse = evaluate_arima_model(dataset, order)\n",
        "\t\t\t\t\tif mse < best_score:\n",
        "\t\t\t\t\t\tbest_score, best_cfg = mse, order\n",
        "\t\t\t\t\tprint('ARIMA%s MSE=%.3f' % (order,mse))\n",
        "\t\t\t\texcept:\n",
        "\t\t\t\t\tcontinue\n",
        "\tprint('Best ARIMA%s MSE=%.3f' % (best_cfg, best_score))\n",
        "\tprint('RMSE = %.2f'%(sqrt(best_score)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhnals0vjYZV",
        "outputId": "b3c8cbcb-7e8e-4d9c-f8f1-0b17cb4635dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "import warnings\n",
        "\n",
        "p_values = range(0, 10)\n",
        "d_values = range(0,1)\n",
        "q_values = range(0,1)\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "evaluate_models(dataset_values, p_values, d_values, q_values)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "ARIMA(0, 0, 0) MSE=16.130\n",
            "ARIMA(1, 0, 0) MSE=6.262\n",
            "ARIMA(2, 0, 0) MSE=6.216\n",
            "ARIMA(3, 0, 0) MSE=5.981\n",
            "ARIMA(4, 0, 0) MSE=5.850\n",
            "ARIMA(5, 0, 0) MSE=5.706\n",
            "ARIMA(6, 0, 0) MSE=5.631\n",
            "ARIMA(7, 0, 0) MSE=5.558\n",
            "Best ARIMA(7, 0, 0) MSE=5.558\n",
            "RMSE = 2.36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dTfkNltso65"
      },
      "source": [
        "## **Train Test Split**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ1JAkj8XyrM",
        "outputId": "03e3adc9-a67f-4a47-92c5-d462f3cd866c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "lag = 7\n",
        "\n",
        "raw_values = dataset.values\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "diff_values"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [-2.8000000000000007]\n",
              "1         [0.9000000000000021]\n",
              "2         [-4.200000000000001]\n",
              "3          [1.200000000000001]\n",
              "4                        [0.0]\n",
              "                 ...          \n",
              "3644     [-0.5999999999999996]\n",
              "3645    [-0.40000000000000036]\n",
              "3646    [-0.09999999999999964]\n",
              "3647      [2.1999999999999993]\n",
              "3648     [-2.6999999999999993]\n",
              "Length: 3649, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqrf2FT9YLzV",
        "outputId": "4977239c-30d5-4871-b90a-14dec9f0cfa0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        }
      },
      "source": [
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[0.9000000000000021]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.9000000000000021]</td>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[-4.200000000000001]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-4.200000000000001]</td>\n",
              "      <td>[0.9000000000000021]</td>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[1.200000000000001]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1.200000000000001]</td>\n",
              "      <td>[-4.200000000000001]</td>\n",
              "      <td>[0.9000000000000021]</td>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>[0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3644</th>\n",
              "      <td>[1.6999999999999993]</td>\n",
              "      <td>[2.9000000000000004]</td>\n",
              "      <td>[-3.9000000000000004]</td>\n",
              "      <td>[0.7000000000000011]</td>\n",
              "      <td>[0.09999999999999964]</td>\n",
              "      <td>[-2.3000000000000007]</td>\n",
              "      <td>[0.7000000000000011]</td>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "      <td>[1.6999999999999993]</td>\n",
              "      <td>[2.9000000000000004]</td>\n",
              "      <td>[-3.9000000000000004]</td>\n",
              "      <td>[0.7000000000000011]</td>\n",
              "      <td>[0.09999999999999964]</td>\n",
              "      <td>[-2.3000000000000007]</td>\n",
              "      <td>[-0.40000000000000036]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3646</th>\n",
              "      <td>[-0.40000000000000036]</td>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "      <td>[1.6999999999999993]</td>\n",
              "      <td>[2.9000000000000004]</td>\n",
              "      <td>[-3.9000000000000004]</td>\n",
              "      <td>[0.7000000000000011]</td>\n",
              "      <td>[0.09999999999999964]</td>\n",
              "      <td>[-0.09999999999999964]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3647</th>\n",
              "      <td>[-0.09999999999999964]</td>\n",
              "      <td>[-0.40000000000000036]</td>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "      <td>[1.6999999999999993]</td>\n",
              "      <td>[2.9000000000000004]</td>\n",
              "      <td>[-3.9000000000000004]</td>\n",
              "      <td>[0.7000000000000011]</td>\n",
              "      <td>[2.1999999999999993]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>[2.1999999999999993]</td>\n",
              "      <td>[-0.09999999999999964]</td>\n",
              "      <td>[-0.40000000000000036]</td>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "      <td>[1.6999999999999993]</td>\n",
              "      <td>[2.9000000000000004]</td>\n",
              "      <td>[-3.9000000000000004]</td>\n",
              "      <td>[-2.6999999999999993]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3649 rows Ã— 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0  ...                       0\n",
              "0                        NaN  ...   [-2.8000000000000007]\n",
              "1      [-2.8000000000000007]  ...    [0.9000000000000021]\n",
              "2       [0.9000000000000021]  ...    [-4.200000000000001]\n",
              "3       [-4.200000000000001]  ...     [1.200000000000001]\n",
              "4        [1.200000000000001]  ...                   [0.0]\n",
              "...                      ...  ...                     ...\n",
              "3644    [1.6999999999999993]  ...   [-0.5999999999999996]\n",
              "3645   [-0.5999999999999996]  ...  [-0.40000000000000036]\n",
              "3646  [-0.40000000000000036]  ...  [-0.09999999999999964]\n",
              "3647  [-0.09999999999999964]  ...    [2.1999999999999993]\n",
              "3648    [2.1999999999999993]  ...   [-2.6999999999999993]\n",
              "\n",
              "[3649 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPRtOw5QYQld",
        "outputId": "0939a56c-2680-40c3-891a-cf214037094a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "supervised_values = supervised.values[lag:,:]\n",
        "supervised_values"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[array([1.6]), array([0.]), array([0.]), ..., array([0.9]),\n",
              "        array([-2.8]), array([4.4])],\n",
              "       [array([4.4]), array([1.6]), array([0.]), ..., array([-4.2]),\n",
              "        array([0.9]), array([-1.8])],\n",
              "       [array([-1.8]), array([4.4]), array([1.6]), ..., array([1.2]),\n",
              "        array([-4.2]), array([-3.8])],\n",
              "       ...,\n",
              "       [array([-0.4]), array([-0.6]), array([1.7]), ..., array([0.7]),\n",
              "        array([0.1]), array([-0.1])],\n",
              "       [array([-0.1]), array([-0.4]), array([-0.6]), ..., array([-3.9]),\n",
              "        array([0.7]), array([2.2])],\n",
              "       [array([2.2]), array([-0.1]), array([-0.4]), ..., array([2.9]),\n",
              "        array([-3.9]), array([-2.7])]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdBliluYYWOh"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behU8o0PYZg7"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1)) # Range hasil scaling menjadi angka diantara -1 hingga 1\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpdkWwehYH8n"
      },
      "source": [
        "# Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsJGBXaQQwFB",
        "outputId": "811d2ef2-0746-4757-b1bc-d2d4bf7b10b1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history = model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0699 - val_loss: 0.0595\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0622 - val_loss: 0.0563\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0558\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0556\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0555\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0553\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0551\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0547\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0541\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0531\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0569 - val_loss: 0.0518\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0555 - val_loss: 0.0504\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0543 - val_loss: 0.0493\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0534 - val_loss: 0.0483\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0526 - val_loss: 0.0476\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0471\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0516 - val_loss: 0.0467\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0513 - val_loss: 0.0464\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0510 - val_loss: 0.0462\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0459\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0458\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0456\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0455\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0454\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0454\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0454\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0453\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0452\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0451\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0451\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0450\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0451\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0450\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0450\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0450\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0449\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0449\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0449\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0450\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0449\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0451\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0449\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0449\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0449\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0447\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0449\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0449\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0447\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0452\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0452\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0447\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0447\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0447\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0451\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0452\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJuCimMs0Xlw",
        "outputId": "a41de8a0-7dc5-4098-b8a2-dd806e6b1d95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss = model.evaluate(feature_test, label_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.0447\n",
            "Test loss: 0.044723011553287506\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgx1IuNdcfY6",
        "outputId": "c599d1ad-51a8-4a6c-c875-696c3299b89a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_dataframe = pd.DataFrame(history.history)\n",
        "history_dataframe['epoch'] = history.epoch\n",
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>894</th>\n",
              "      <td>0.049216</td>\n",
              "      <td>0.044650</td>\n",
              "      <td>894</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>824</th>\n",
              "      <td>0.049219</td>\n",
              "      <td>0.044652</td>\n",
              "      <td>824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>0.049227</td>\n",
              "      <td>0.044653</td>\n",
              "      <td>460</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>790</th>\n",
              "      <td>0.049197</td>\n",
              "      <td>0.044655</td>\n",
              "      <td>790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>927</th>\n",
              "      <td>0.049203</td>\n",
              "      <td>0.044655</td>\n",
              "      <td>927</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.060257</td>\n",
              "      <td>0.055464</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.060457</td>\n",
              "      <td>0.055620</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.060760</td>\n",
              "      <td>0.055808</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.062158</td>\n",
              "      <td>0.056301</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.069908</td>\n",
              "      <td>0.059508</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "894  0.049216  0.044650    894\n",
              "824  0.049219  0.044652    824\n",
              "460  0.049227  0.044653    460\n",
              "790  0.049197  0.044655    790\n",
              "927  0.049203  0.044655    927\n",
              "..        ...       ...    ...\n",
              "4    0.060257  0.055464      4\n",
              "3    0.060457  0.055620      3\n",
              "2    0.060760  0.055808      2\n",
              "1    0.062158  0.056301      1\n",
              "0    0.069908  0.059508      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUuHpMPfchpG",
        "outputId": "e9fc770e-f9e5-4332-b277-2dc27546912e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history) # epoch vs loss graph"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkeaQDxbZHYI"
      },
      "source": [
        "# Deeper model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRjbIlSnZIVu",
        "outputId": "1f0ab661-10f2-4760-d7ba-99e27e8e52f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model = Sequential()\n",
        "deeper_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model.add(Dense(5, activation='relu'))\n",
        "deeper_model.add(Dense(1))\n",
        "deeper_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history = deeper_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0673 - val_loss: 0.0580\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0618 - val_loss: 0.0566\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0611 - val_loss: 0.0561\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0608 - val_loss: 0.0559\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0606 - val_loss: 0.0557\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0604 - val_loss: 0.0556\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0603 - val_loss: 0.0555\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0602 - val_loss: 0.0554\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0552\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0599 - val_loss: 0.0551\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0548\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0545\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0535\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0529\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0572 - val_loss: 0.0522\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0565 - val_loss: 0.0514\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0558 - val_loss: 0.0505\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0550 - val_loss: 0.0499\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0544 - val_loss: 0.0492\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0538 - val_loss: 0.0487\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0531 - val_loss: 0.0482\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0528 - val_loss: 0.0477\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0522 - val_loss: 0.0472\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0518 - val_loss: 0.0469\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0514 - val_loss: 0.0465\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0512 - val_loss: 0.0462\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0508 - val_loss: 0.0461\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0507 - val_loss: 0.0457\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0504 - val_loss: 0.0456\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0503 - val_loss: 0.0454\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0453\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0501 - val_loss: 0.0453\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0500 - val_loss: 0.0452\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0499 - val_loss: 0.0452\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0452\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0451\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0450\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0450\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0449\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0449\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0498 - val_loss: 0.0449\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0497 - val_loss: 0.0449\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0449\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0453\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0449\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0496 - val_loss: 0.0448\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0449\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0448\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0447\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0447\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0449\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0447\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0449\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0450\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0449\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0450\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0450\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0450\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0447\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0449\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0495 - val_loss: 0.0449\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0447\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0449\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0450\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0490 - val_loss: 0.0450\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0448\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0451\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0494 - val_loss: 0.0447\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0447\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0448\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0491 - val_loss: 0.0450\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0450\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0449\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0448\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0447\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0492 - val_loss: 0.0449\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0447\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxksLfsjZlK2",
        "outputId": "e3fb7dad-5ad9-4c96-9f6e-7393d94326c3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "deeper_history_dataframe = pd.DataFrame(deeper_model_history.history)\n",
        "deeper_history_dataframe['epoch'] = deeper_model_history.epoch\n",
        "deeper_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>925</th>\n",
              "      <td>0.049234</td>\n",
              "      <td>0.044655</td>\n",
              "      <td>925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>775</th>\n",
              "      <td>0.049230</td>\n",
              "      <td>0.044657</td>\n",
              "      <td>775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>892</th>\n",
              "      <td>0.049206</td>\n",
              "      <td>0.044658</td>\n",
              "      <td>892</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>0.049200</td>\n",
              "      <td>0.044659</td>\n",
              "      <td>658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>601</th>\n",
              "      <td>0.049269</td>\n",
              "      <td>0.044659</td>\n",
              "      <td>601</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.060608</td>\n",
              "      <td>0.055739</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.060798</td>\n",
              "      <td>0.055915</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.061106</td>\n",
              "      <td>0.056142</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.061842</td>\n",
              "      <td>0.056576</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.067318</td>\n",
              "      <td>0.057967</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "925  0.049234  0.044655    925\n",
              "775  0.049230  0.044657    775\n",
              "892  0.049206  0.044658    892\n",
              "658  0.049200  0.044659    658\n",
              "601  0.049269  0.044659    601\n",
              "..        ...       ...    ...\n",
              "4    0.060608  0.055739      4\n",
              "3    0.060798  0.055915      3\n",
              "2    0.061106  0.056142      2\n",
              "1    0.061842  0.056576      1\n",
              "0    0.067318  0.057967      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uv9EnMgt--_",
        "outputId": "fed86eae-ff5c-4346-94c9-c122d6c44d42",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(deeper_model_history) # epoch vs loss graph"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqcjp3avYLgU"
      },
      "source": [
        "# Wider model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82rebSGUYNK2",
        "outputId": "e04567aa-7943-4fcf-e16a-3fed58c05fd5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "wider_model = Sequential()\n",
        "wider_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model.add(Dense(1))\n",
        "wider_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history = wider_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0650 - val_loss: 0.0524\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0549 - val_loss: 0.0489\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0520 - val_loss: 0.0473\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0506 - val_loss: 0.0467\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0502 - val_loss: 0.0463\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0460\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0493 - val_loss: 0.0457\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0461\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0485 - val_loss: 0.0459\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0488 - val_loss: 0.0456\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0457\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0484 - val_loss: 0.0462\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0482 - val_loss: 0.0454\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0480 - val_loss: 0.0454\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0481 - val_loss: 0.0455\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.0456\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0479 - val_loss: 0.0465\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0454\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0476 - val_loss: 0.0453\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0475 - val_loss: 0.0456\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0455\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.0455\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0474 - val_loss: 0.0456\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.0455\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0475 - val_loss: 0.0457\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0471 - val_loss: 0.0456\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0472 - val_loss: 0.0453\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0470 - val_loss: 0.0456\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0469 - val_loss: 0.0457\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0469 - val_loss: 0.0456\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.0458\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0455\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.0456\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.0458\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0468 - val_loss: 0.0453\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.0454\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.0454\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.0454\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0467 - val_loss: 0.0458\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0466 - val_loss: 0.0454\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0459\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0465 - val_loss: 0.0459\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0456\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0463 - val_loss: 0.0457\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0464 - val_loss: 0.0457\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0454\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.0457\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0456\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0462 - val_loss: 0.0457\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.0457\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.0459\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0458\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0458\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0459 - val_loss: 0.0459\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0460 - val_loss: 0.0460\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0458 - val_loss: 0.0458\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0458 - val_loss: 0.0461\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.0463\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.0462\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.0458\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.0460\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0456 - val_loss: 0.0460\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0456 - val_loss: 0.0462\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0456 - val_loss: 0.0461\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0460\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0460\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0461\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0461\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.0461\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0460\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0457 - val_loss: 0.0464\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0462\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0455 - val_loss: 0.0465\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0465\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0454 - val_loss: 0.0465\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0468\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0471\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0464\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.0465\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0462\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0450 - val_loss: 0.0466\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0469\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0468\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0452 - val_loss: 0.0464\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0453 - val_loss: 0.0464\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0451 - val_loss: 0.0464\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0465\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0464\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0473\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0450 - val_loss: 0.0465\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0449 - val_loss: 0.0469\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0466\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0450 - val_loss: 0.0467\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0466\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0468\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0467\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0466\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0465\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0467\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0465\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0469\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0469\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0444 - val_loss: 0.0469\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0471\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0448 - val_loss: 0.0468\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0446 - val_loss: 0.0473\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0474\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0447 - val_loss: 0.0468\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0469\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0469\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0468\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.0469\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0476\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0445 - val_loss: 0.0468\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0477\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0475\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.0469\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.0468\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0443 - val_loss: 0.0468\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0474\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0471\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.0473\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0472\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0469\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0469\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0468\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0471\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0470\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0470\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0469\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0471\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0471\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0440 - val_loss: 0.0471\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0483\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0470\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0470\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0472\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0478\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0442 - val_loss: 0.0471\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0470\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0474\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0471\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0475\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0477\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0474\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0438 - val_loss: 0.0476\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0439 - val_loss: 0.0472\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0472\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0473\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0475\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0480\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0477\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0478\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0481\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0475\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0474\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0437 - val_loss: 0.0473\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0474\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0476\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0478\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0441 - val_loss: 0.0473\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0435 - val_loss: 0.0474\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0473\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0476\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0485\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0436 - val_loss: 0.0474\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0474\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0479\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0477\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0475\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0479\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0474\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0477\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0473\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0477\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0474\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0476\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0478\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0474\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0477\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0474\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0433 - val_loss: 0.0476\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0475\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0475\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0474\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.0479\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0474\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0477\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0475\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0475\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0483\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0476\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0477\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0434 - val_loss: 0.0479\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0477\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0474\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0475\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.0479\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0476\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0432 - val_loss: 0.0476\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0477\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0480\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0480\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0478\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0478\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.0476\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0483\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0475\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0480\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0483\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0478\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0486\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0431 - val_loss: 0.0479\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0481\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0480\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0477\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.0483\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0429 - val_loss: 0.0482\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0479\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0481\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0480\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0478\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0479\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0479\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0482\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0481\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0479\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0479\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0482\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0430 - val_loss: 0.0481\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0480\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0479\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0485\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0427 - val_loss: 0.0481\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0479\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0482\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0480\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0487\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0493\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0485\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0481\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0489\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0425 - val_loss: 0.0484\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0484\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0482\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0428 - val_loss: 0.0482\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0480\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0480\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0426 - val_loss: 0.0480\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0480\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0480\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0481\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0482\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0485\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0480\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0486\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0479\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0487\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0481\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0483\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0485\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0483\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0481\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0491\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0482\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0482\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0484\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0486\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0487\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0485\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0487\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0485\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0484\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0484\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0484\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0487\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0484\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0485\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0482\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0491\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0424 - val_loss: 0.0491\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0489\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0486\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0481\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0485\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0487\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0483\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0484\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0486\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0423 - val_loss: 0.0488\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0485\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0487\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0486\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0487\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0489\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0487\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0505\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0422 - val_loss: 0.0486\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0484\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0484\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0486\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0490\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0484\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0485\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0497\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0485\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0487\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0487\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0487\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0484\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0499\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0488\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0487\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0492\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0495\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0488\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0489\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0484\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0486\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0483\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0486\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0485\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0488\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0501\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0487\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0496\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0500\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0491\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0486\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0487\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0420 - val_loss: 0.0491\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0421 - val_loss: 0.0492\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0487\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0489\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0487\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0486\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0489\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0488\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0487\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0487\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0488\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0489\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0493\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0491\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0419 - val_loss: 0.0488\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0486\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0487\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0490\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0495\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0490\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0494\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0489\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0488\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0495\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0490\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0493\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0493\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0417 - val_loss: 0.0491\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0496\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0493\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0490\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0496\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0498\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0491\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0493\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0490\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0491\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0492\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0493\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0498\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0490\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0492\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0494\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0499\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0490\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0492\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0418 - val_loss: 0.0491\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0494\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0496\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0489\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0502\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0494\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0492\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0495\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0416 - val_loss: 0.0497\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0490\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0493\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0492\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0495\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0494\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0491\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0498\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0502\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0492\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0499\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0491\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0511\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0496\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0493\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0415 - val_loss: 0.0495\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0500\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0491\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0504\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0498\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0492\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0497\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0499\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0494\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0512\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0494\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0498\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0496\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0500\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0493\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0496\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0495\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0501\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0495\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0493\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0511\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0492\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0492\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0498\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0494\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0496\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0495\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0494\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0496\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0497\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0498\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0498\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0495\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0494\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0499\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0496\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0494\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0496\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0497\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0496\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0500\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0499\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0493\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0501\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0494\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0494\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0494\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0495\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0498\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0495\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0495\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0510\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0495\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0499\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0512\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0500\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0500\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0494\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0499\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0499\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0502\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0496\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0498\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0495\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0499\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0507\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0498\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0499\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0498\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0501\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0501\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0501\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0497\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0503\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0413 - val_loss: 0.0496\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0496\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0497\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0497\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0499\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0505\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0500\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0502\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0497\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0513\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0499\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0511\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0498\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0498\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0512\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0495\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0503\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0500\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0501\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0499\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0496\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0504\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0497\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0497\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0497\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0501\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0504\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0495\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0497\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0504\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0500\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0503\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0500\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0498\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0520\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0503\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0500\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0499\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0502\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0499\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0498\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0497\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0501\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0503\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0498\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0507\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0508\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0499\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0504\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0501\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0516\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0502\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0502\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0498\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0500\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0502\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0515\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0498\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0503\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0503\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0500\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0514\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0411 - val_loss: 0.0501\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0502\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0499\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0503\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0500\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0508\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0500\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0500\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0409 - val_loss: 0.0505\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0497\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0503\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0509\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0509\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0507\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0501\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0500\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0500\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0504\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0498\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0519\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0497\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0502\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0513\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0512\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0499\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0511\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0500\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0499\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0500\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0508\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0414 - val_loss: 0.0508\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0501\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0506\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0506\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0500\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0502\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0501\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0507\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0504\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0504\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0506\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0502\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0503\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0502\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0500\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0501\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0506\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0499\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0522\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0412 - val_loss: 0.0504\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0502\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0504\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0506\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0507\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0509\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0504\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0507\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0505\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0502\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0500\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0509\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0511\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0521\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0408 - val_loss: 0.0504\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0502\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0501\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0506\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0503\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0502\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0505\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0509\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0502\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0506\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0507\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0507\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0501\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0503\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0501\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0503\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0506\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0503\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0503\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0510\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0506\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0504\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0503\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0524\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0504\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0506\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0507\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0506\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0510\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0503\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0503\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0509\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0511\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0503\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0508\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0504\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0512\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0507\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0523\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0506\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0507\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0504\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0511\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0514\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0505\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0505\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0507\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0507\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0517\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0506\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0504\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0510\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0505\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0505\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0507\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0510\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0505\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0511\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0507\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0510\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0512\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0512\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0507\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0504\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0505\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0509\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0504\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0504\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0504\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0509\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0512\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0504\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0509\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0511\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0509\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0504\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0520\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0505\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0509\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0507\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0513\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0511\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0507\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0506\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0513\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0506\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0514\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0507\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0512\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0509\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0513\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0511\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0518\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0512\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0510\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0509\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0513\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0510\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0521\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0508\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0516\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0516\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0508\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0508\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0514\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0513\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0506\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0508\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0509\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0509\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0406 - val_loss: 0.0510\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0513\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0511\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0508\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0512\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0508\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0512\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0517\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0509\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0518\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0507\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0509\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0522\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0509\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0511\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0513\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0510\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0507\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0514\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0505\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0511\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0509\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0508\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0508\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0517\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0509\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0520\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0511\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0507\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0510\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0522\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0514\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0517\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0506\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0509\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0509\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0506\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0515\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0507\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0511\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0513\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0510\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0530\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0407 - val_loss: 0.0515\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0410 - val_loss: 0.0513\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0510\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0515\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0518\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0514\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0515\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0511\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0507\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0507\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0509\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0508\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0512\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0514\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0510\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0508\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0512\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0509\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0513\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0542\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0519\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0510\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0514\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0523\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0510\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0505\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0515\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0508\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0511\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0506\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0508\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0513\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0507\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0514\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0510\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0507\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0513\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0507\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0506\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0510\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0514\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0508\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0521\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0511\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0514\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0526\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0522\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0517\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0518\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0508\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0513\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0514\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0512\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0511\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0509\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0508\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0509\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0505\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0519\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0522\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0512\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0512\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0510\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0512\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0513\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0520\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0512\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0509\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0511\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0510\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0533\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0516\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0512\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0514\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0512\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0509\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0510\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0512\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0514\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0512\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0520\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0510\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0514\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0518\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0512\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0530\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0513\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0513\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0522\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0510\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0522\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0509\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0522\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0514\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0513\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0404 - val_loss: 0.0510\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0515\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0517\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0509\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0508\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0512\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0513\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0515\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0511\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0405 - val_loss: 0.0519\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0517\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0512\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0519\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0516\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0517\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0512\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0514\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0519\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0510\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0513\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0512\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0518\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0525\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0522\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0511\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0513\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0512\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0514\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0524\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0513\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0524\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0516\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0516\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0519\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0509\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0516\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0511\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0514\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0518\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0512\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0516\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0518\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0516\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0522\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0512\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0515\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0510\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0521\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0514\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0511\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0515\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0524\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0515\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0509\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0394 - val_loss: 0.0513\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0514\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0523\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0515\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0528\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0398 - val_loss: 0.0519\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0520\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0512\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0527\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0400 - val_loss: 0.0514\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0523\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0402 - val_loss: 0.0539\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0528\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0513\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0515\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0518\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0522\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0517\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0511\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0513\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0524\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0399 - val_loss: 0.0515\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0513\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0395 - val_loss: 0.0514\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0396 - val_loss: 0.0516\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0403 - val_loss: 0.0511\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0401 - val_loss: 0.0514\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmrJSX3NYYh5",
        "outputId": "555b779d-435b-4117-b479-6524caf2a34f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "wider_history_dataframe = pd.DataFrame(wider_model_history.history)\n",
        "wider_history_dataframe['epoch'] = wider_model_history.epoch\n",
        "wider_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0.047608</td>\n",
              "      <td>0.045281</td>\n",
              "      <td>18</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>0.046792</td>\n",
              "      <td>0.045304</td>\n",
              "      <td>34</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.047161</td>\n",
              "      <td>0.045342</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.047812</td>\n",
              "      <td>0.045378</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.046664</td>\n",
              "      <td>0.045379</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>816</th>\n",
              "      <td>0.039996</td>\n",
              "      <td>0.052971</td>\n",
              "      <td>816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>905</th>\n",
              "      <td>0.039555</td>\n",
              "      <td>0.052999</td>\n",
              "      <td>905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>888</th>\n",
              "      <td>0.039879</td>\n",
              "      <td>0.053298</td>\n",
              "      <td>888</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>983</th>\n",
              "      <td>0.040155</td>\n",
              "      <td>0.053918</td>\n",
              "      <td>983</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>836</th>\n",
              "      <td>0.040066</td>\n",
              "      <td>0.054240</td>\n",
              "      <td>836</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "18   0.047608  0.045281     18\n",
              "34   0.046792  0.045304     34\n",
              "26   0.047161  0.045342     26\n",
              "17   0.047812  0.045378     17\n",
              "37   0.046664  0.045379     37\n",
              "..        ...       ...    ...\n",
              "816  0.039996  0.052971    816\n",
              "905  0.039555  0.052999    905\n",
              "888  0.039879  0.053298    888\n",
              "983  0.040155  0.053918    983\n",
              "836  0.040066  0.054240    836\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozMuE8RlbV-c"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NiKK3E-Z_Ke",
        "outputId": "c5595a6f-6c78-41af-963d-bd836a35cdf1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Reshape menjadi (jumlah sample, time steps, jumlah feature)\n",
        "# Time steps: jumlah lag, gunakan default 1\n",
        "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history = lstm_model.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 0.0651 - val_loss: 0.0543\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0574 - val_loss: 0.0513\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0544 - val_loss: 0.0486\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0521 - val_loss: 0.0468\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0506 - val_loss: 0.0458\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0497 - val_loss: 0.0451\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0491 - val_loss: 0.0448\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0488 - val_loss: 0.0447\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0487 - val_loss: 0.0446\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0486 - val_loss: 0.0448\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0484 - val_loss: 0.0447\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0450\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0485 - val_loss: 0.0446\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0446\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0449\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0482 - val_loss: 0.0448\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0447\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0481 - val_loss: 0.0448\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0480 - val_loss: 0.0449\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0479 - val_loss: 0.0448\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0448\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0479 - val_loss: 0.0450\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0449\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0449\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0477 - val_loss: 0.0449\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0478 - val_loss: 0.0453\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0451\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0453\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0476 - val_loss: 0.0451\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0451\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0475 - val_loss: 0.0452\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0474 - val_loss: 0.0453\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0456\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0454\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0452\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0471 - val_loss: 0.0453\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0473 - val_loss: 0.0454\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0472 - val_loss: 0.0454\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0454\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0455\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0457\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0455\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0470 - val_loss: 0.0454\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0455\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0456\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0456\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0469 - val_loss: 0.0457\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0468 - val_loss: 0.0456\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0457\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0461\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0467 - val_loss: 0.0457\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0466 - val_loss: 0.0458\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0457\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0461\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0457\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0459\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0465 - val_loss: 0.0458\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0464 - val_loss: 0.0459\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0460\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0460\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0460\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0460\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0459\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0461\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0466\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0463 - val_loss: 0.0462\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0460\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0467\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0462 - val_loss: 0.0460\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0461\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0462\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0461\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0462\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0461 - val_loss: 0.0461\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0466\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0462\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0464\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0464\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0465\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0464\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0459 - val_loss: 0.0465\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0463\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0464\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0457 - val_loss: 0.0464\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0458 - val_loss: 0.0464\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0468\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0467\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0458 - val_loss: 0.0465\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0465\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0468\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0465\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0465\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0466\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0466\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0472\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0457 - val_loss: 0.0467\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0456 - val_loss: 0.0468\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0468\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0467\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0455 - val_loss: 0.0470\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0468\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0455 - val_loss: 0.0467\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0468\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0471\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0454 - val_loss: 0.0468\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0469\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0469\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0469\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0470\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0472\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0470\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0471\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0453 - val_loss: 0.0470\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0470\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0471\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0471\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0471\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0472\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0473\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0472\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0452 - val_loss: 0.0471\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0471\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0473\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0472\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0472\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0474\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0451 - val_loss: 0.0473\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0472\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0472\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0473\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0473\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0472\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0473\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0472\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0475\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0472\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0473\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0472\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0449 - val_loss: 0.0472\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0450 - val_loss: 0.0474\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0474\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0473\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0473\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0474\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0473\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0473\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0473\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0475\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0474\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0474\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0475\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0474\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0476\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0475\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0476\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0448 - val_loss: 0.0475\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0446 - val_loss: 0.0474\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0447 - val_loss: 0.0474\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0474\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0474\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0474\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0477\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0475\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0476\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0445 - val_loss: 0.0475\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0475\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0478\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0476\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0477\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0476\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0478\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0477\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0476\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0477\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0477\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0443 - val_loss: 0.0480\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0477\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0477\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0482\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0476\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0477\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0480\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0444 - val_loss: 0.0477\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0478\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0479\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0477\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0483\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0477\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0442 - val_loss: 0.0477\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0480\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0479\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0478\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0442 - val_loss: 0.0479\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0480\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0478\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0478\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0479\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0480\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0441 - val_loss: 0.0479\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0479\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0440 - val_loss: 0.0479\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0480\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0440 - val_loss: 0.0478\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0479\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0480\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0485\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0479\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0479\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0479\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0483\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0479\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0480\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0481\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0483\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0481\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0481\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0482\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0480\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0481\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0482\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0439 - val_loss: 0.0483\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0480\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0438 - val_loss: 0.0480\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0482\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0484\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0482\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0484\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0483\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0489\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0482\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0481\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0481\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0481\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0490\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0436 - val_loss: 0.0483\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0437 - val_loss: 0.0481\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0481\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0483\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0485\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0435 - val_loss: 0.0484\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0486\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0483\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0484\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0482\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0482\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0482\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0483\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0483\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0486\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0482\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0433 - val_loss: 0.0484\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0485\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0482\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0483\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0483\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0483\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0484\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0486\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0433 - val_loss: 0.0486\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0434 - val_loss: 0.0483\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0484\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0432 - val_loss: 0.0485\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0486\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0487\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0485\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0486\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0483\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0485\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0489\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0487\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0486\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0430 - val_loss: 0.0485\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0485\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0486\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0485\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0431 - val_loss: 0.0487\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0485\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0491\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0488\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0489\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0488\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0486\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0489\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0486\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0429 - val_loss: 0.0487\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0495\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0430 - val_loss: 0.0487\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0487\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0491\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0489\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0488\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0488\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0488\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0487\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0487\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0489\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0428 - val_loss: 0.0488\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0489\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0487\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0427 - val_loss: 0.0492\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0488\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0495\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0489\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0490\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0489\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0488\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0426 - val_loss: 0.0487\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0488\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0488\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0489\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0487\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0491\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0488\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0488\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0489\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0490\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0489\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0491\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0490\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0493\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0490\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0491\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0490\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0490\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0493\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0489\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0488\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0491\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0425 - val_loss: 0.0490\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0490\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0492\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0423 - val_loss: 0.0488\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0489\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0492\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0424 - val_loss: 0.0489\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0490\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0492\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0489\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0491\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0493\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0494\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0495\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0498\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0492\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0491\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0489\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0491\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0422 - val_loss: 0.0492\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0492\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0421 - val_loss: 0.0496\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0491\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0491\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0490\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0493\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0491\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0492\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0492\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0496\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0420 - val_loss: 0.0492\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0493\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0419 - val_loss: 0.0499\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0491\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0493\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0490\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0491\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0418 - val_loss: 0.0492\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0491\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0493\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0492\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0493\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0497\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0496\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0492\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0499\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0417 - val_loss: 0.0498\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0491\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0496\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0493\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0494\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0493\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0494\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0493\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0493\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0492\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0494\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0416 - val_loss: 0.0493\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0492\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0495\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0500\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0493\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0492\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0414 - val_loss: 0.0496\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0494\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0506\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0502\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0494\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0494\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0499\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0415 - val_loss: 0.0495\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0496\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0496\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0496\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0502\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0495\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0495\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0496\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0494\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0496\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0496\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0495\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0495\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0497\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0495\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0497\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0497\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0498\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0499\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0413 - val_loss: 0.0498\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0497\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0508\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0496\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0496\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0498\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0497\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0499\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0412 - val_loss: 0.0507\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0497\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0497\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0499\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0497\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0496\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0408 - val_loss: 0.0495\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0501\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0499\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0498\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0498\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0411 - val_loss: 0.0498\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0504\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0498\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0499\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0504\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0499\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0500\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0505\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0503\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0507\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0410 - val_loss: 0.0501\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0500\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0500\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0409 - val_loss: 0.0499\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0501\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0509\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0408 - val_loss: 0.0502\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0520\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0499\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0500\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0504\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0502\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0501\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0506\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0505\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0509\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0503\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0405 - val_loss: 0.0502\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0504\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0406 - val_loss: 0.0502\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0505\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0502\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0503\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0509\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0508\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0404 - val_loss: 0.0503\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0512\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0407 - val_loss: 0.0502\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0502\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0503\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0503\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0508\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0504\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0402 - val_loss: 0.0503\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0505\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0504\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0504\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0509\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0512\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0505\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0506\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0513\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0514\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0512\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0512\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0403 - val_loss: 0.0505\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0504\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0507\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0508\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0507\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0505\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0505\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0506\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0506\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0509\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0504\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0504\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0508\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0514\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0505\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0506\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0518\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0508\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0505\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0505\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0507\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0510\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0507\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0513\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0505\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0514\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0508\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0510\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0504\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0514\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0508\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0507\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0400 - val_loss: 0.0510\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0506\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0507\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0507\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0506\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0507\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0510\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0506\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0401 - val_loss: 0.0506\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0521\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0505\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0504\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0525\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0397 - val_loss: 0.0509\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0398 - val_loss: 0.0507\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0506\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0505\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0507\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0509\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0510\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0514\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0510\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0509\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0399 - val_loss: 0.0510\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0396 - val_loss: 0.0521\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0518\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0395 - val_loss: 0.0509\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0507\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0506\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0507\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0507\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0511\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0509\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0515\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0509\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0508\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0394 - val_loss: 0.0509\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0519\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0510\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0512\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0507\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0509\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0509\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0508\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0505\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0513\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0515\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0511\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0508\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0509\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0513\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0515\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0393 - val_loss: 0.0511\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0392 - val_loss: 0.0527\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0508\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0511\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0509\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0392 - val_loss: 0.0511\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0510\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0514\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0513\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0509\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0509\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0519\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0510\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0520\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0512\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0509\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0509\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0509\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0511\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0515\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0509\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0510\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0511\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0510\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0511\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0391 - val_loss: 0.0516\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0510\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0523\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0390 - val_loss: 0.0508\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0511\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0513\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0388 - val_loss: 0.0512\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0512\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0513\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0513\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0511\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0514\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0509\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0511\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0515\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0516\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0512\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0388 - val_loss: 0.0516\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0511\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0512\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0389 - val_loss: 0.0510\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0510\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0514\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0513\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0513\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0521\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0512\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0512\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0525\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0512\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0387 - val_loss: 0.0512\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0519\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0516\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0516\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0516\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0518\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0516\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0513\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0513\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0519\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0513\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0516\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0516\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0517\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0511\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0516\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0385 - val_loss: 0.0512\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0516\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0516\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0514\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0515\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0513\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0520\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0517\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0518\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0518\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0515\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0386 - val_loss: 0.0513\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0384 - val_loss: 0.0518\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0516\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0515\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0384 - val_loss: 0.0518\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0515\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0514\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0512\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0526\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0520\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0521\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0515\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0515\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0515\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0518\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0516\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0516\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0516\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0522\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0520\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0521\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0518\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0381 - val_loss: 0.0524\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0519\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0526\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0519\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0383 - val_loss: 0.0520\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0518\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0518\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0519\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0522\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0518\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0520\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0382 - val_loss: 0.0519\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0520\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0522\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0534\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0520\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0523\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0522\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0520\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0526\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0379 - val_loss: 0.0524\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0524\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0526\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0521\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0519\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0524\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0528\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0526\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0523\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0521\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0524\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0521\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0527\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0522\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0521\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0523\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0523\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0524\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0524\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0522\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0526\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0377 - val_loss: 0.0519\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0526\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0533\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0380 - val_loss: 0.0520\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0525\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0519\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0523\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0524\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0522\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0522\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0525\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0522\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0526\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0523\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0378 - val_loss: 0.0524\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0535\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0379 - val_loss: 0.0525\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0529\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0527\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0522\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0522\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0527\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0527\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0523\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0527\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0536\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0526\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0376 - val_loss: 0.0524\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0523\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0522\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0526\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0523\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0528\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0527\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0522\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0528\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0375 - val_loss: 0.0534\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0528\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0374 - val_loss: 0.0527\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0527\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0526\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0527\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0524\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0534\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0553\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0524\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0528\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0529\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0528\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0539\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0377 - val_loss: 0.0526\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0531\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0526\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0531\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0524\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0526\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0529\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0527\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0529\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0528\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0525\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0533\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0371 - val_loss: 0.0534\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0536\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0373 - val_loss: 0.0527\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0531\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0531\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0531\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0527\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0531\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0527\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0533\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0526\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0534\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0529\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0532\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0529\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0528\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0539\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0534\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0526\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0526\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0527\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0531\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0535\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0528\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0533\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0542\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0529\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0533\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0529\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0525\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0529\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0535\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0548\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0533\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0532\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0529\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0532\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0531\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0532\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0375 - val_loss: 0.0540\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0530\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0529\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0529\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0530\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0529\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0372 - val_loss: 0.0527\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0532\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0525\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0529\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0539\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0534\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0530\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0530\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0373 - val_loss: 0.0528\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0528\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0531\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0535\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0532\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0530\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0538\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0530\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0527\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0526\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0529\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0529\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0531\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0538\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0370 - val_loss: 0.0529\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0531\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0539\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0533\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0532\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0533\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0536\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0534\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0528\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0533\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0535\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0529\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0535\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0371 - val_loss: 0.0528\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0369 - val_loss: 0.0528\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0532\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0531\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0366 - val_loss: 0.0533\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0365 - val_loss: 0.0529\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0368 - val_loss: 0.0530\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0531\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0534\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0536\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0534\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0538\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0532\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0529\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0534\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0530\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0536\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0535\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0539\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0532\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0530\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0532\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0545\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0542\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0545\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0529\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0533\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0535\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0530\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0533\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0532\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0537\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0550\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0534\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0535\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0534\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0539\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0542\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0538\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0536\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0540\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0366 - val_loss: 0.0544\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0533\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0533\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0536\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0531\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0533\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0535\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0538\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0540\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0540\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0541\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0537\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0535\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0538\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0537\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0536\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0542\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0541\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0539\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0538\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0536\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0542\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0538\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0538\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0363 - val_loss: 0.0534\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0536\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0542\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0542\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0537\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0537\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0533\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0540\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0539\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0536\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0538\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0542\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0544\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0542\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0533\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0539\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0365 - val_loss: 0.0540\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0535\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0536\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0539\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0538\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0542\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0572\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0367 - val_loss: 0.0538\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0540\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0541\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0540\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0541\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0543\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0541\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0540\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0539\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0539\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0549\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0547\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0540\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0559\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0538\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0551\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0540\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0545\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0545\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0364 - val_loss: 0.0541\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0363 - val_loss: 0.0543\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0359 - val_loss: 0.0547\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0362 - val_loss: 0.0545\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0541\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0541\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0552\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0360 - val_loss: 0.0541\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0358 - val_loss: 0.0547\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0361 - val_loss: 0.0536\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwE413j8bCIr",
        "outputId": "8f0ebbbd-16f8-4bc5-85ea-f4688f6ea6d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "lstm_history_dataframe = pd.DataFrame(lstm_model_history.history)\n",
        "lstm_history_dataframe['epoch'] = lstm_model_history.epoch\n",
        "lstm_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0.048713</td>\n",
              "      <td>0.044639</td>\n",
              "      <td>8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>0.048187</td>\n",
              "      <td>0.044649</td>\n",
              "      <td>13</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>0.048494</td>\n",
              "      <td>0.044649</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.048445</td>\n",
              "      <td>0.044667</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>0.048817</td>\n",
              "      <td>0.044696</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>986</th>\n",
              "      <td>0.035986</td>\n",
              "      <td>0.055095</td>\n",
              "      <td>986</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>0.036000</td>\n",
              "      <td>0.055233</td>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>784</th>\n",
              "      <td>0.037116</td>\n",
              "      <td>0.055290</td>\n",
              "      <td>784</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>984</th>\n",
              "      <td>0.035998</td>\n",
              "      <td>0.055940</td>\n",
              "      <td>984</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>969</th>\n",
              "      <td>0.036120</td>\n",
              "      <td>0.057224</td>\n",
              "      <td>969</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "8    0.048713  0.044639      8\n",
              "13   0.048187  0.044649     13\n",
              "12   0.048494  0.044649     12\n",
              "10   0.048445  0.044667     10\n",
              "7    0.048817  0.044696      7\n",
              "..        ...       ...    ...\n",
              "986  0.035986  0.055095    986\n",
              "996  0.036000  0.055233    996\n",
              "784  0.037116  0.055290    784\n",
              "984  0.035998  0.055940    984\n",
              "969  0.036120  0.057224    969\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjQM8Yvqdjrx",
        "outputId": "64b21aa4-afb0-4586-ce54-1f77c0942eb0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(lstm_model_history)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSYnJgj964Wk"
      },
      "source": [
        "# **Kesimpulan**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4v7qpOP7Vq5"
      },
      "source": [
        "Berdasarkan perhitungan diatas dengan lag terbaik yakni 7 (berdasarkan hasil perhitungan ARIMA) didapatkan hasil:\n",
        "\n",
        "```\n",
        "Baseline Model: Val_loss 0.044650 Epoch 894\n",
        "Deeper Model: Val_loss 0.044655 Epoch 925\n",
        "Wider Model: Val_loss 0.045281 Epoch 18\n",
        "LSTM: Val_loss 0.044639 Epoch 8\n",
        "```\n",
        "melihat dari hasil val_loss yang ada maka dapat di simpulkan **LSTM** mendapatkan hasil yang **terbaik** karena val_loss semakin kecil semakin baik dan juga jika di bandingkan antara lag nya maka lag 7 lebih baik di bandingkan lag 1 ini membuktikan bahwa lag mempengaruhi tingkat akurasi dalam model atau arsitektur TimeSeries.\n"
      ]
    }
  ]
}