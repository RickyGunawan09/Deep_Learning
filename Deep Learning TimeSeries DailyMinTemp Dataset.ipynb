{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment17_RickyGunawan_DailyMinTemp.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "s2tRPzAKv1jR"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sb\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7wa24lkVU4hu"
      },
      "source": [
        "def parser(x):\n",
        "\treturn datetime.strptime(x, '%Y-%m-%d')\n",
        " \n",
        "def timeseries_to_supervised(data, lag=1):\n",
        "    df = pd.DataFrame(data)\n",
        "    columns = [df.shift(i) for i in range(1, lag+1)]\n",
        "    columns.append(df)\n",
        "    df = pd.concat(columns, axis=1)\n",
        "    return df\n",
        "\n",
        "def difference(dataset, interval=1):\n",
        "\tdiff = list()\n",
        "\tfor i in range(interval, len(dataset)):\n",
        "\t\tvalue = dataset[i] - dataset[i - interval]\n",
        "\t\tdiff.append(value)\n",
        "\treturn pd.Series(diff)\n",
        "\n",
        "def plot_loss(history):\n",
        "  plt.plot(history.history['loss'], label='loss')\n",
        "  plt.plot(history.history['val_loss'], label='val_loss')\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.legend()\n",
        "  plt.grid(True)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tS0ZGKXpW5o0"
      },
      "source": [
        "# **Dataset Daily Min Temp**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "soC1JGsfW-4B",
        "outputId": "5724cc88-5c02-4a0f-a772-07589ab66513",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/BCML/datasets/daily-min-temperatures.csv', header=0, parse_dates=[0], index_col=0, squeeze=False, date_parser=parser)\n",
        "dataset.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Temp</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1981-01-01</th>\n",
              "      <td>20.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-02</th>\n",
              "      <td>17.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-03</th>\n",
              "      <td>18.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-04</th>\n",
              "      <td>14.6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981-01-05</th>\n",
              "      <td>15.8</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            Temp\n",
              "Date            \n",
              "1981-01-01  20.7\n",
              "1981-01-02  17.9\n",
              "1981-01-03  18.8\n",
              "1981-01-04  14.6\n",
              "1981-01-05  15.8"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv_Me1QwXaoB",
        "outputId": "43e07d6b-5473-48e0-ab6a-63119372c8d0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "dataset.plot()\n",
        "plt.show()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ1JAkj8XyrM",
        "outputId": "5c2106fe-f7d3-488f-dcf6-8aed3f2406ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "lag = 1\n",
        "\n",
        "raw_values = dataset.values\n",
        "diff_values = difference(raw_values, 1)\n",
        "\n",
        "diff_values"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        [-2.8000000000000007]\n",
              "1         [0.9000000000000021]\n",
              "2         [-4.200000000000001]\n",
              "3          [1.200000000000001]\n",
              "4                        [0.0]\n",
              "                 ...          \n",
              "3644     [-0.5999999999999996]\n",
              "3645    [-0.40000000000000036]\n",
              "3646    [-0.09999999999999964]\n",
              "3647      [2.1999999999999993]\n",
              "3648     [-2.6999999999999993]\n",
              "Length: 3649, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hqrf2FT9YLzV",
        "outputId": "039d67ab-93be-4d63-c755-f0cf9e7e0a5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "supervised = timeseries_to_supervised(diff_values, lag)\n",
        "supervised"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NaN</td>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[-2.8000000000000007]</td>\n",
              "      <td>[0.9000000000000021]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[0.9000000000000021]</td>\n",
              "      <td>[-4.200000000000001]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[-4.200000000000001]</td>\n",
              "      <td>[1.200000000000001]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[1.200000000000001]</td>\n",
              "      <td>[0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3644</th>\n",
              "      <td>[1.6999999999999993]</td>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3645</th>\n",
              "      <td>[-0.5999999999999996]</td>\n",
              "      <td>[-0.40000000000000036]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3646</th>\n",
              "      <td>[-0.40000000000000036]</td>\n",
              "      <td>[-0.09999999999999964]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3647</th>\n",
              "      <td>[-0.09999999999999964]</td>\n",
              "      <td>[2.1999999999999993]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3648</th>\n",
              "      <td>[2.1999999999999993]</td>\n",
              "      <td>[-2.6999999999999993]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3649 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                           0                       0\n",
              "0                        NaN   [-2.8000000000000007]\n",
              "1      [-2.8000000000000007]    [0.9000000000000021]\n",
              "2       [0.9000000000000021]    [-4.200000000000001]\n",
              "3       [-4.200000000000001]     [1.200000000000001]\n",
              "4        [1.200000000000001]                   [0.0]\n",
              "...                      ...                     ...\n",
              "3644    [1.6999999999999993]   [-0.5999999999999996]\n",
              "3645   [-0.5999999999999996]  [-0.40000000000000036]\n",
              "3646  [-0.40000000000000036]  [-0.09999999999999964]\n",
              "3647  [-0.09999999999999964]    [2.1999999999999993]\n",
              "3648    [2.1999999999999993]   [-2.6999999999999993]\n",
              "\n",
              "[3649 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DPRtOw5QYQld",
        "outputId": "0b419c9a-54d7-41f0-80cf-0455332df724",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "supervised_values = supervised.values[lag:,:]\n",
        "supervised_values"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[array([-2.8]), array([0.9])],\n",
              "       [array([0.9]), array([-4.2])],\n",
              "       [array([-4.2]), array([1.2])],\n",
              "       ...,\n",
              "       [array([-0.4]), array([-0.1])],\n",
              "       [array([-0.1]), array([2.2])],\n",
              "       [array([2.2]), array([-2.7])]], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdBliluYYWOh"
      },
      "source": [
        "split_percentage = 0.75\n",
        "\n",
        "train_size = int(split_percentage * len(supervised_values))\n",
        "\n",
        "train, test = supervised_values[0:train_size], supervised_values[train_size:len(supervised_values)]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "behU8o0PYZg7"
      },
      "source": [
        "scaler = MinMaxScaler(feature_range=(-1, 1)) # Range hasil scaling menjadi angka diantara -1 hingga 1\n",
        "scaler = scaler.fit(train)\n",
        "\n",
        "train_scaled = scaler.transform(train)\n",
        "test_scaled = scaler.transform(test)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cpdkWwehYH8n"
      },
      "source": [
        "# Baseline model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsJGBXaQQwFB",
        "outputId": "48523ca3-a6ce-402d-a7d4-0d912c26d557",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "feature_train, label_train = train_scaled[:, 0:-1], train_scaled[:, -1]\n",
        "feature_test, label_test = test_scaled[:, 0:-1], test_scaled[:, -1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "model.add(Dense(1))\n",
        "model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "history = model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0958 - val_loss: 0.0704\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0666 - val_loss: 0.0577\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0550\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0546\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0544\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0544\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0544\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0546\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0546\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0545\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0545\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0545\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0545\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJuCimMs0Xlw",
        "outputId": "b407afdb-cb22-4023-e7b4-49c15e259c75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "loss = model.evaluate(feature_test, label_test, verbose=2)\n",
        "\n",
        "print(\"Test loss:\", loss)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "29/29 - 0s - loss: 0.0545\n",
            "Test loss: 0.05448964610695839\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xgx1IuNdcfY6",
        "outputId": "8430e35b-3cea-4833-972f-fcde991bbad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "history_dataframe = pd.DataFrame(history.history)\n",
        "history_dataframe['epoch'] = history.epoch\n",
        "history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0.058687</td>\n",
              "      <td>0.054410</td>\n",
              "      <td>15</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>0.058667</td>\n",
              "      <td>0.054412</td>\n",
              "      <td>38</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.058664</td>\n",
              "      <td>0.054413</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>0.058662</td>\n",
              "      <td>0.054414</td>\n",
              "      <td>37</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>0.058657</td>\n",
              "      <td>0.054414</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>0.058717</td>\n",
              "      <td>0.054573</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.058858</td>\n",
              "      <td>0.054576</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.059999</td>\n",
              "      <td>0.055019</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.066636</td>\n",
              "      <td>0.057653</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.095805</td>\n",
              "      <td>0.070401</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "15   0.058687  0.054410     15\n",
              "38   0.058667  0.054412     38\n",
              "19   0.058664  0.054413     19\n",
              "37   0.058662  0.054414     37\n",
              "17   0.058657  0.054414     17\n",
              "..        ...       ...    ...\n",
              "349  0.058717  0.054573    349\n",
              "3    0.058858  0.054576      3\n",
              "2    0.059999  0.055019      2\n",
              "1    0.066636  0.057653      1\n",
              "0    0.095805  0.070401      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUuHpMPfchpG",
        "outputId": "c52d8950-ff15-4428-d34d-6d0a05385094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(history) # epoch vs loss graph"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GkeaQDxbZHYI"
      },
      "source": [
        "# Deeper model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRjbIlSnZIVu",
        "outputId": "66e7c430-23f7-4c4f-91fe-ba8ad5fecc9b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 1\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "deeper_model = Sequential()\n",
        "deeper_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "deeper_model.add(Dense(5, activation='relu'))\n",
        "deeper_model.add(Dense(1))\n",
        "deeper_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "deeper_model_history = deeper_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0638 - val_loss: 0.0553\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0605 - val_loss: 0.0550\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0601 - val_loss: 0.0549\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0600 - val_loss: 0.0548\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0548\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0598 - val_loss: 0.0547\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0597 - val_loss: 0.0547\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0596 - val_loss: 0.0546\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0595 - val_loss: 0.0547\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0595 - val_loss: 0.0546\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0594 - val_loss: 0.0546\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0545\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0545\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0545\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0545\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0545\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0593 - val_loss: 0.0545\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0592 - val_loss: 0.0546\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0544\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0545\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0545\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0592 - val_loss: 0.0544\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0591 - val_loss: 0.0544\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0544\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0543\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0543\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0589 - val_loss: 0.0542\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0588 - val_loss: 0.0542\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0542\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0587 - val_loss: 0.0541\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0586 - val_loss: 0.0542\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0540\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0539\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0543\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0539\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0545\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BxksLfsjZlK2",
        "outputId": "68068e43-7281-4535-91cb-28c5440dce34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "deeper_history_dataframe = pd.DataFrame(deeper_model_history.history)\n",
        "deeper_history_dataframe['epoch'] = deeper_model_history.epoch\n",
        "deeper_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>840</th>\n",
              "      <td>0.058131</td>\n",
              "      <td>0.053804</td>\n",
              "      <td>840</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>903</th>\n",
              "      <td>0.058180</td>\n",
              "      <td>0.053811</td>\n",
              "      <td>903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>906</th>\n",
              "      <td>0.058104</td>\n",
              "      <td>0.053812</td>\n",
              "      <td>906</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>968</th>\n",
              "      <td>0.058106</td>\n",
              "      <td>0.053812</td>\n",
              "      <td>968</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>786</th>\n",
              "      <td>0.058100</td>\n",
              "      <td>0.053817</td>\n",
              "      <td>786</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.059966</td>\n",
              "      <td>0.054788</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.059817</td>\n",
              "      <td>0.054807</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.060143</td>\n",
              "      <td>0.054875</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.060461</td>\n",
              "      <td>0.054989</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.063789</td>\n",
              "      <td>0.055333</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "840  0.058131  0.053804    840\n",
              "903  0.058180  0.053811    903\n",
              "906  0.058104  0.053812    906\n",
              "968  0.058106  0.053812    968\n",
              "786  0.058100  0.053817    786\n",
              "..        ...       ...    ...\n",
              "3    0.059966  0.054788      3\n",
              "4    0.059817  0.054807      4\n",
              "2    0.060143  0.054875      2\n",
              "1    0.060461  0.054989      1\n",
              "0    0.063789  0.055333      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Uv9EnMgt--_",
        "outputId": "04ced19c-d4c1-4667-fd24-38418dfe899e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(deeper_model_history) # epoch vs loss graph"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cqcjp3avYLgU"
      },
      "source": [
        "# Wider model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "82rebSGUYNK2",
        "outputId": "c810aa35-5cfc-4394-d7fd-c0e1913a5d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "neurons = 50\n",
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "wider_model = Sequential()\n",
        "wider_model.add(Dense(neurons, activation='relu', input_dim=feature_train.shape[1]))\n",
        "wider_model.add(Dense(1))\n",
        "wider_model.compile(loss='mean_squared_error', optimizer='adam')\n",
        "wider_model_history = wider_model.fit(feature_train, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test, label_test))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0619 - val_loss: 0.0542\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0590 - val_loss: 0.0541\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0586 - val_loss: 0.0541\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0583 - val_loss: 0.0537\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0537\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0538\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0544\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0546\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0544\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0544\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0547\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0580 - val_loss: 0.0543\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0538\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0538\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0538\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0540\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0539\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0544\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0543\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0539\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0541\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0543\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0539\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0542\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0544\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0543\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0544\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0541\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0575 - val_loss: 0.0540\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0573 - val_loss: 0.0542\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0540\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 1ms/step - loss: 0.0574 - val_loss: 0.0541\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0574 - val_loss: 0.0542\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmrJSX3NYYh5",
        "outputId": "d5e4cc28-f81f-426b-ac1c-a76aa769a41b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "wider_history_dataframe = pd.DataFrame(wider_model_history.history)\n",
        "wider_history_dataframe['epoch'] = wider_model_history.epoch\n",
        "wider_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>0.058331</td>\n",
              "      <td>0.053731</td>\n",
              "      <td>14</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>0.058006</td>\n",
              "      <td>0.053749</td>\n",
              "      <td>19</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>0.057884</td>\n",
              "      <td>0.053765</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>0.057931</td>\n",
              "      <td>0.053767</td>\n",
              "      <td>25</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>0.057888</td>\n",
              "      <td>0.053768</td>\n",
              "      <td>28</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>0.057885</td>\n",
              "      <td>0.054409</td>\n",
              "      <td>147</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>855</th>\n",
              "      <td>0.057496</td>\n",
              "      <td>0.054422</td>\n",
              "      <td>855</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>962</th>\n",
              "      <td>0.057442</td>\n",
              "      <td>0.054427</td>\n",
              "      <td>962</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.057875</td>\n",
              "      <td>0.054583</td>\n",
              "      <td>100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.057707</td>\n",
              "      <td>0.054707</td>\n",
              "      <td>198</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "14   0.058331  0.053731     14\n",
              "19   0.058006  0.053749     19\n",
              "21   0.057884  0.053765     21\n",
              "25   0.057931  0.053767     25\n",
              "28   0.057888  0.053768     28\n",
              "..        ...       ...    ...\n",
              "147  0.057885  0.054409    147\n",
              "855  0.057496  0.054422    855\n",
              "962  0.057442  0.054427    962\n",
              "100  0.057875  0.054583    100\n",
              "198  0.057707  0.054707    198\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ozMuE8RlbV-c"
      },
      "source": [
        "# **LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NiKK3E-Z_Ke",
        "outputId": "03f0064b-5007-4619-a407-a63eec860fca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "epoch = 1000\n",
        "batch_size = 32\n",
        "\n",
        "# Reshape menjadi (jumlah sample, time steps, jumlah feature)\n",
        "# Time steps: jumlah lag, gunakan default 1\n",
        "# https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/\n",
        "feature_train_reshaped = np.reshape(feature_train, (feature_train.shape[0], 1, feature_train.shape[1]))\n",
        "feature_test_reshaped = np.reshape(feature_test, (feature_test.shape[0], 1, feature_test.shape[1]))\n",
        "\n",
        "lstm_model = Sequential()\n",
        "lstm_model.add(LSTM(50, activation='relu', input_dim=feature_train.shape[1])) # 50 LSTM Block\n",
        "lstm_model.add(Dense(1))\n",
        "lstm_model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "\n",
        "lstm_model_history = lstm_model.fit(feature_train_reshaped, label_train, epochs=epoch, batch_size=batch_size, validation_data=(feature_test_reshaped, label_test))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/1000\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 0.0647 - val_loss: 0.0550\n",
            "Epoch 2/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0592 - val_loss: 0.0542\n",
            "Epoch 3/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0588 - val_loss: 0.0540\n",
            "Epoch 4/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0539\n",
            "Epoch 5/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 6/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 7/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 8/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 9/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0544\n",
            "Epoch 10/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0585 - val_loss: 0.0540\n",
            "Epoch 11/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 12/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0543\n",
            "Epoch 13/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 14/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 15/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0542\n",
            "Epoch 16/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 17/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 18/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 19/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 20/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 21/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 22/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 23/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 24/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 25/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 26/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 27/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 28/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 29/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 30/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 31/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 32/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 33/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 34/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 35/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0540\n",
            "Epoch 36/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 37/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 38/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 39/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 40/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 41/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 42/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 43/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 44/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0543\n",
            "Epoch 45/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 46/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 47/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 48/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 49/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 50/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 51/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 52/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 53/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 54/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 55/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 56/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 57/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 58/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 59/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 60/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 61/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 62/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 63/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 64/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 65/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 66/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 67/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 68/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 69/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 70/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 71/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 72/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 73/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 74/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 75/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 76/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 77/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 78/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 79/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 80/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 81/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 82/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 83/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 84/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 85/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 86/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 87/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 88/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 89/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 90/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 91/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 92/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 93/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 94/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 95/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 96/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0539\n",
            "Epoch 97/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 98/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 99/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 100/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 101/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 102/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 103/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0545\n",
            "Epoch 104/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 105/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 106/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 107/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 108/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 109/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 110/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 111/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0542\n",
            "Epoch 112/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 113/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 114/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 115/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 116/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 117/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 118/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 119/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 120/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 121/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 122/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 123/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 124/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 125/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 126/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0584 - val_loss: 0.0541\n",
            "Epoch 127/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 128/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 129/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 130/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 131/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 132/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 133/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 134/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 135/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 136/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 137/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 138/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0540\n",
            "Epoch 139/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 140/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 141/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 142/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 143/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 144/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 145/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 146/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 147/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 148/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 149/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 150/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 151/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 152/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 153/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 154/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 155/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 156/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 157/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 158/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 159/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 160/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 161/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 162/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 163/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 164/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 165/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 166/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 167/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 168/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 169/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 170/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 171/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 172/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 173/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 174/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 175/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 176/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 177/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 178/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 179/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 180/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 181/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 182/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 183/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 184/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 185/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 186/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 187/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 188/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 189/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 190/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 191/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0541\n",
            "Epoch 192/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 193/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0583 - val_loss: 0.0539\n",
            "Epoch 194/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 195/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 196/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0542\n",
            "Epoch 197/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 198/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 199/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 200/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 201/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 202/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 203/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 204/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 205/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 206/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 207/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 208/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 209/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 210/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0540\n",
            "Epoch 211/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 212/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 213/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0541\n",
            "Epoch 214/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 215/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 216/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 217/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 218/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 219/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 220/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 221/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 222/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 223/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 224/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 225/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 226/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 227/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 228/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 229/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 230/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 231/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 232/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 233/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0582 - val_loss: 0.0539\n",
            "Epoch 234/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 235/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0544\n",
            "Epoch 236/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 237/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 238/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 239/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 240/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 241/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0549\n",
            "Epoch 242/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0583 - val_loss: 0.0541\n",
            "Epoch 243/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 244/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 245/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 246/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0539\n",
            "Epoch 247/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 248/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 249/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 250/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 251/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 252/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 253/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 254/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0540\n",
            "Epoch 255/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 256/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 257/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 258/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 259/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 260/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 261/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 262/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 263/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 264/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 265/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 266/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 267/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 268/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 269/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 270/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 271/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 272/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 273/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 274/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 275/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 276/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 277/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 278/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 279/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 280/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 281/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 282/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 283/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 284/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 285/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 286/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 287/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 288/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 289/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 290/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 291/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 292/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 293/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 294/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0541\n",
            "Epoch 295/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 296/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 297/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0542\n",
            "Epoch 298/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 299/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 300/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 301/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 302/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 303/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 304/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 305/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 306/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 307/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 308/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 309/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 310/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 311/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 312/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 313/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 314/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 315/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 316/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 317/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 318/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 319/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 320/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 321/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 322/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 323/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 324/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0544\n",
            "Epoch 325/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 326/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 327/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 328/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 329/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 330/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 331/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 332/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 333/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 334/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 335/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 336/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 337/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 338/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 339/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 340/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 341/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 342/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 343/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 344/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 345/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 346/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 347/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 348/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 349/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 350/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0545\n",
            "Epoch 351/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 352/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 353/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 354/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 355/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 356/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 357/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 358/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 359/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 360/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 361/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 362/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 363/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 364/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 365/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 366/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 367/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 368/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 369/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 370/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 371/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 372/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 373/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 374/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 375/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 376/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 377/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 378/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 379/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 380/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 381/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 382/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 383/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 384/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 385/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 386/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 387/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 388/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 389/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 390/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 391/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 392/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 393/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 394/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 395/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 396/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 397/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 398/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 399/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 400/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 401/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 402/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 403/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 404/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 405/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 406/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 407/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 408/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 409/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0542\n",
            "Epoch 410/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 411/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 412/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 413/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 414/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 415/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 416/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 417/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 418/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 419/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 420/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 421/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 422/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 423/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 424/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 425/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 426/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 427/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 428/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 429/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 430/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0545\n",
            "Epoch 431/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 432/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 433/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 434/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 435/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 436/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 437/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 438/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 439/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 440/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 441/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 442/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 443/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 444/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 445/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 446/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 447/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 448/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 449/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0544\n",
            "Epoch 450/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 451/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 452/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 453/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 454/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 455/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 456/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 457/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 458/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 459/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 460/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 461/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 462/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 463/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 464/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 465/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 466/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 467/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 468/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 469/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 470/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 471/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 472/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 473/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 474/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 475/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 476/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 477/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 478/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 479/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 480/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 481/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 482/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 483/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 484/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 485/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 486/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 487/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 488/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 489/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 490/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 491/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 492/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 493/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 494/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 495/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 496/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 497/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 498/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 499/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 500/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 501/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 502/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 503/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 504/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 505/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 506/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0543\n",
            "Epoch 507/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 508/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 509/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 510/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 511/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 512/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 513/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 514/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 515/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 516/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 517/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 518/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 519/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 520/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 521/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 522/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 523/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 524/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 525/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 526/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 527/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 528/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 529/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 530/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 531/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 532/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0544\n",
            "Epoch 533/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 534/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 535/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0581 - val_loss: 0.0538\n",
            "Epoch 536/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 537/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 538/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 539/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 540/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 541/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 542/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 543/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 544/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 545/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 546/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 547/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 548/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0544\n",
            "Epoch 549/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 550/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 551/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 552/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 553/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 554/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 555/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 556/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 557/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 558/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 559/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 560/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 561/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 562/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 563/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 564/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0580 - val_loss: 0.0538\n",
            "Epoch 565/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 566/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 567/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 568/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 569/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 570/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 571/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 572/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 573/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 574/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 575/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 576/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 577/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 578/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0539\n",
            "Epoch 579/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 580/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 581/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 582/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 583/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 584/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 585/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 586/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 587/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 588/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 589/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 590/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 591/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 592/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 593/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 594/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 595/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 596/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 597/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 598/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 599/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 600/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 601/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 602/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 603/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 604/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 605/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 606/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 607/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 608/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 609/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 610/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 611/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 612/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0544\n",
            "Epoch 613/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 614/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 615/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 616/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 617/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 618/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 619/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 620/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 621/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 622/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 623/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 624/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 625/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 626/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 627/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 628/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 629/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 630/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 631/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 632/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 633/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 634/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 635/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 636/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 637/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 638/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0538\n",
            "Epoch 639/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 640/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 641/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 642/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 643/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 644/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 645/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 646/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 647/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 648/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 649/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0538\n",
            "Epoch 650/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 651/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 652/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 653/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 654/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 655/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 656/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 657/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 658/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 659/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 660/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 661/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 662/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 663/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 664/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 665/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 666/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 667/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 668/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 669/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 670/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 671/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 672/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 673/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 674/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 675/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 676/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 677/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 678/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 679/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 680/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 681/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 682/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 683/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 684/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 685/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 686/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 687/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 688/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 689/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 690/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 691/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 692/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 693/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 694/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 695/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 696/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 697/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 698/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 699/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 700/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 701/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 702/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0541\n",
            "Epoch 703/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 704/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 705/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 706/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 707/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 708/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 709/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 710/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 711/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 712/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 713/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 714/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 715/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 716/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 717/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 718/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 719/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 720/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 721/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 722/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 723/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 724/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 725/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 726/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 727/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 728/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 729/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 730/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 731/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 732/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 733/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 734/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 735/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 736/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 737/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 738/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 739/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 740/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 741/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 742/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 743/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 744/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 745/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 746/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 747/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 748/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 749/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 750/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 751/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 752/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 753/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 754/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 755/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 756/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 757/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 758/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 759/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 760/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 761/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 762/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 763/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 764/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 765/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 766/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 767/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 768/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 769/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 770/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 771/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 772/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 773/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 774/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 775/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 776/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 777/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 778/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 779/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 780/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 781/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 782/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 783/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 784/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 785/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 786/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 787/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 788/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 789/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 790/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 791/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 792/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 793/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 794/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 795/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 796/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 797/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 798/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 799/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 800/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 801/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 802/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 803/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 804/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 805/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 806/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 807/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 808/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 809/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 810/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 811/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 812/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 813/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 814/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 815/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 816/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0540\n",
            "Epoch 817/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 818/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 819/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 820/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 821/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 822/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 823/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 824/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 825/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 826/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 827/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0580 - val_loss: 0.0540\n",
            "Epoch 828/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 829/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 830/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 831/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 832/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 833/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 834/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 835/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 836/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 837/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 838/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 839/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 840/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 841/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 842/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 843/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 844/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 845/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0542\n",
            "Epoch 846/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 847/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 848/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 849/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 850/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 851/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 852/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 853/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 854/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 855/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 856/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 857/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 858/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 859/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 860/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 861/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 862/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 863/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 864/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 865/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 866/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 867/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 868/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 869/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 870/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 871/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 872/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 873/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 874/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 875/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 876/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0544\n",
            "Epoch 877/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 878/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 879/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 880/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 881/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 882/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 883/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 884/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 885/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 886/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 887/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 888/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 889/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 890/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 891/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0539\n",
            "Epoch 892/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0579 - val_loss: 0.0539\n",
            "Epoch 893/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 894/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 895/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 896/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 897/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 898/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 899/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 900/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0539\n",
            "Epoch 901/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 902/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 903/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 904/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 905/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 906/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 907/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 908/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 909/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 910/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 911/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 912/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 913/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 914/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 915/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 916/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 917/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0539\n",
            "Epoch 918/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 919/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 920/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 921/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0543\n",
            "Epoch 922/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0540\n",
            "Epoch 923/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 924/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 925/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 926/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 927/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 928/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 929/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 930/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 931/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 932/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 933/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 934/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 935/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 936/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 937/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 938/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 939/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 940/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 941/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 942/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 943/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 944/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 945/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 946/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 947/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 948/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 949/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 950/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 951/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 952/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0543\n",
            "Epoch 953/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 954/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 955/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 956/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 957/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 958/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 959/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 960/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 961/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 962/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 963/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 964/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 965/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 966/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 967/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 968/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 969/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 970/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 971/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 972/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 973/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 974/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 975/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 976/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 977/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 978/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0578 - val_loss: 0.0541\n",
            "Epoch 979/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 980/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 981/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 982/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 983/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 984/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 985/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0542\n",
            "Epoch 986/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 987/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 988/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 989/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 990/1000\n",
            "86/86 [==============================] - 0s 5ms/step - loss: 0.0577 - val_loss: 0.0541\n",
            "Epoch 991/1000\n",
            "86/86 [==============================] - 0s 4ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 992/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 993/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 994/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 995/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0542\n",
            "Epoch 996/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0577 - val_loss: 0.0540\n",
            "Epoch 997/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0540\n",
            "Epoch 998/1000\n",
            "86/86 [==============================] - 0s 2ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 999/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0576 - val_loss: 0.0541\n",
            "Epoch 1000/1000\n",
            "86/86 [==============================] - 0s 3ms/step - loss: 0.0577 - val_loss: 0.0540\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zwE413j8bCIr",
        "outputId": "0347bfc5-2431-4cb5-dc6b-1d1dffae228d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "lstm_history_dataframe = pd.DataFrame(lstm_model_history.history)\n",
        "lstm_history_dataframe['epoch'] = lstm_model_history.epoch\n",
        "lstm_history_dataframe.sort_values(by='val_loss', ascending=True)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>0.057941</td>\n",
              "      <td>0.053774</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>0.057866</td>\n",
              "      <td>0.053777</td>\n",
              "      <td>312</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>0.058022</td>\n",
              "      <td>0.053779</td>\n",
              "      <td>321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>0.057859</td>\n",
              "      <td>0.053780</td>\n",
              "      <td>340</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>0.057929</td>\n",
              "      <td>0.053782</td>\n",
              "      <td>341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>0.057860</td>\n",
              "      <td>0.054458</td>\n",
              "      <td>349</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>0.058066</td>\n",
              "      <td>0.054489</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>0.057927</td>\n",
              "      <td>0.054511</td>\n",
              "      <td>429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>0.057861</td>\n",
              "      <td>0.054925</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.064746</td>\n",
              "      <td>0.054967</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss  val_loss  epoch\n",
              "351  0.057941  0.053774    351\n",
              "312  0.057866  0.053777    312\n",
              "321  0.058022  0.053779    321\n",
              "340  0.057859  0.053780    340\n",
              "341  0.057929  0.053782    341\n",
              "..        ...       ...    ...\n",
              "349  0.057860  0.054458    349\n",
              "102  0.058066  0.054489    102\n",
              "429  0.057927  0.054511    429\n",
              "240  0.057861  0.054925    240\n",
              "0    0.064746  0.054967      0\n",
              "\n",
              "[1000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjQM8Yvqdjrx",
        "outputId": "11d0ad44-f4d3-4354-a825-c96ee3b2c286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "plot_loss(lstm_model_history)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSYnJgj964Wk"
      },
      "source": [
        "# **Kesimpulan**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4v7qpOP7Vq5"
      },
      "source": [
        "Berdasarkan perhitungan diatas didapatkan hasil:\n",
        "\n",
        "```\n",
        "Baseline Model: Val_loss 0.054410 Epoch 15\n",
        "Deeper Model: Val_loss 0.053804 Epoch 840\n",
        "Wider Model: Val_loss 0.053731 Epoch 14\n",
        "LSTM: Val_loss 0.053774 Epoch 351\n",
        "```\n",
        "melihat dari hasil val_loss yang ada maka dapat di simpulkan **wider model** mendapatkan hasil yang **terbaik** meskipun perbedaannya hanya sedikit tetapi karena val_loss semakin kecil semakin baik jadi kita ambil yang paling kecil.\n"
      ]
    }
  ]
}